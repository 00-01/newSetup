## gpu monitor
    watch -d -n 0.1 nvidia-smi

## gpu memmory error fix
    GPU_SET = 0

    gpus = tf.config.experimental.list_physical_devices('GPU')

    if gpus:
        try:
            if GPU_SET == 0:
        ## 1 필요한 만큼 메모리를 런타임에 할당
                for gpu in gpus:
                    tf.config.experimental.set_memory_growth(gpu, True)
            elif GPU_SET == 1:
        ## 2 GPU에 할당되는 전체 메모리 크기를 제한
                tf.config.experimental.set_virtual_device_configuration(
                        gpus[0],
                        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=6144)])
            logical_gpus = tf.config.experimental.list_logical_devices('GPU')
            print(len(gpus), "Physical GPUs,", len(logical_gpus), "Logical GPUs")
        except RuntimeError as e:
            print(e)
    
### source link
    https://www.tensorflow.org/guide/gpu
    https://inpages.tistory.com/155
